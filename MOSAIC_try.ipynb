{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Activation, Dropout, Flatten, Dense, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6b1c95caeeaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## real time data augmentation ..\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m trainDataGen = ImageDataGenerator(\n\u001b[0m\u001b[0;32m      4\u001b[0m                 \u001b[0mrotation_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[1;31m## rotated image training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mwidth_shift_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "## real time data augmentation ..\n",
    "\n",
    "trainDataGen = ImageDataGenerator(\n",
    "\t\trotation_range = 5,          ## rotated image training\n",
    "\t\twidth_shift_range = 0.1,\n",
    "\t\theight_shift_range = 0.1,   ## shifted image training\n",
    "\t\trescale = 1.0/255,\n",
    "\t\tshear_range = 0.2,\n",
    "\t\t#zoom_range = 0.2,\t\t   ## zoomed image training\n",
    "\t\t#horizontal_flip = False,\n",
    "\t\tfill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)     ### this is basically normalisation (ratio by which each pixel is multiplied)\n",
    "trainGenerator = trainDataGen.flow_from_directory(\n",
    "\t\t\t\"D:\\DevanagariHandwrittenCharacterDataset\\Train\",    ## directory of foler having classes of training sets\n",
    "\t\t\ttarget_size = (32,32),\n",
    "\t\t\tbatch_size = 32,\n",
    "\t\t\tcolor_mode = \"grayscale\",\n",
    "\t\t\tclass_mode = \"categorical\")\n",
    "prev = \"\"\n",
    "labels = [\"ka\",\"kha\",\"ga\",\"gha\",\"kna\",\"cha\",\"chha\",\"ja\",\"jha\",\"yna\",\"t`a\",\"t`ha\",\"d`a\",\"d`ha\",\"adna\",\"ta\",\"tha\",\"da\",\"dha\",\"na\",\"pa\",\"pha\",\"ba\",\"bha\",\"ma\",\"yaw\",\"ra\",\"la\",\"waw\",\"sha\",\"shat\",\"sa\",\"ha\",\"aksha\",\"tra\",\"gya\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "count = 0;\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\t\t\t\"D:\\DevanagariHandwrittenCharacterDataset\\Test\",     ## directory of folder having tests set\n",
    "\t\t\ttarget_size=(32,32),\n",
    "\t\t\tbatch_size=32,\n",
    "\t\t\tcolor_mode = \"grayscale\",\n",
    "\t\t\tclass_mode= 'categorical')\n",
    "\t\t\t\n",
    "model = Sequential()\n",
    "\n",
    "##  introducing different layers + batch normalisation (gaussian curve)\n",
    "#Layer1----------------------------------------------------------\n",
    "model.add(Convolution2D(filters = 32,\n",
    "\t\t\tkernel_size = (3,3),\n",
    "\t\t\tstrides = 1,\n",
    "\t\t\tactivation = \"relu\",\n",
    "\t\t\tinput_shape = (32,32,1)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25)) #\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "\t\t\tstrides=(2, 2),\n",
    "\t\t\tpadding=\"same\"))\n",
    "\n",
    "#Layer2-------------------------------------------------------------\n",
    "model.add(Convolution2D(filters = 32,\n",
    "\t\t\tkernel_size = (3,3),\n",
    "\t\t\tstrides = 1,\n",
    "\t\t\tactivation = \"relu\",\n",
    "\t\t\tinput_shape = (32,32,1)))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D())       #\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "\t\t\tstrides=(2, 2),\n",
    "\t\t\tpadding=\"same\"))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "#Layers 3-----------------------------------------------------------\t\n",
    "model.add(Convolution2D(filters = 64,\n",
    "\t\t\tkernel_size = (3,3),\n",
    "\t\t\tstrides = 1,\n",
    "\t\t\tactivation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "\t\t\tstrides=(2, 2),\n",
    "\t\t\tpadding=\"same\"))\n",
    "\n",
    "\n",
    "#Layer 4--------------------------------------------------\n",
    "model.add(Convolution2D(filters = 64,\n",
    "\t\t\tkernel_size = (3,3),\n",
    "\t\t\tstrides= 1,\n",
    "\t\t\tactivation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "\t\t\tstrides=(2, 2),\n",
    "\t\t\tpadding=\"same\"))\t\t\t\n",
    "\t\t\t\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "#Layer 5---  #### (removable part on the basis of accuracy of result)\n",
    "model.add(Convolution2D(filters = 64,\n",
    "\t\t\tkernel_size = (2,2),\n",
    "\t\t\tstrides= 1,\n",
    "\t\t\tactivation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "\t\t\tstrides=(2, 2),\n",
    "\t\t\tpadding=\"same\"))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,\n",
    "\t\tactivation = \"relu\",\n",
    "\t\tkernel_initializer = \"uniform\"))\n",
    "model.add(BatchNormalization())\t\t\t\n",
    "\n",
    "model.add(Dense(64,\n",
    "\t\tactivation = \"relu\",\n",
    "\t\tkernel_initializer = \"uniform\"))\n",
    "model.add(BatchNormalization())\t\t\t\n",
    "\n",
    "model.add(Dense(46,    # orignally was 46 (letters + digits) but we need 36 outputs\n",
    "\t\tactivation = \"softmax\",\n",
    "\t\tkernel_initializer = \"uniform\"))\t\t\t\n",
    "\t\t\t\n",
    "model.compile(optimizer = \"adam\",\n",
    "\t\tloss = \"categorical_crossentropy\",\n",
    "\t\tmetrics = [\"accuracy\"])\n",
    "\t\t\n",
    "print(model.summary())\n",
    "\n",
    "res=model.fit_generator(\n",
    "\t\ttrainGenerator,\n",
    "\t\tepochs = 25,\n",
    "\t\tsteps_per_epoch = 2,       # 2444\n",
    "\t\tvalidation_data = validation_generator,\n",
    "\t\tvalidation_steps = 432\n",
    "\t\t)\n",
    "\n",
    "%matplotlib inline\n",
    "accu=res.history['accuracy']\n",
    "#val_acc=res.history['val_accuracy']\n",
    "loss=res.history['loss']\n",
    "#val_loss=res.history['val_loss']\n",
    "\n",
    "epochs=range(len(accu)) #No. of epochs\n",
    "\n",
    "# graph plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs,accu,'r',label='Training Accuracy')\n",
    "plt.plot(epochs,val_acc,'g',label='Testing Accuracy')  \n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#Plot training and validation loss per epoch\n",
    "plt.plot(epochs,loss,'r',label='Training Loss')\n",
    "plt.plot(epochs,val_loss,'g',label='Testing Loss')   \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\t\t\n",
    "## saving the model --  we can do one thing is define two functions in a class..\n",
    "# one function will have model preparation..\n",
    "# the other will give results..\n",
    "\n",
    "# model.save(\"HindiModel2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002767634FE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "à¤Ÿ\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "''' [\"ka\",\"kha\",\"ga\",\"gha\",\"kna\",\"cha\",\"chha\",\"ja\",\"jha\",\"yna\",\"t`a\",\"t`ha\",\"d`a\",\"d`ha\",\"adna\",\"ta\",\"tha\",\"da\",\"dha\",\"na\",\"pa\",\"pha\",\"ba\",\"bha\",\"ma\",\"yaw\",\"ra\",\"la\",\"waw\",\"sha\",\"shat\",\"sa\",\"ha\",\"aksha\",\"tra\",\"gya\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "labels =['yna', 't`aa', 't`haa', 'd`aa', 'd`haa', 'a`dna', 'ta', 'tha', 'da', 'dha', 'ka', 'na', 'pa', 'pha', 'ba', 'bha', 'ma', 'yaw', 'ra', 'la', 'waw', 'kha', 'sha', 'shat', 'sa', 'ha', 'aksha', 'tra', 'gya', 'ga', 'gha', 'kna', 'cha', 'chha', 'ja', 'jha', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "'''\n",
    "labels = [u'\\u091E',u'\\u091F',u'\\u0920',u'\\u0921',u'\\u0922',u'\\u0923',u'\\u0924',u'\\u0925',u'\\u0926',u'\\u0927',u'\\u0915',u'\\u0928',u'\\u092A',u'\\u092B',u'\\u092c',u'\\u092d',u'\\u092e',u'\\u092f',u'\\u0930',u'\\u0932',u'\\u0935',u'\\u0916',u'\\u0936',u'\\u0937',u'\\u0938',u'\\u0939','ksha','tra','gya',u'\\u0917',u'\\u0918',u'\\u0919',u'\\u091a',u'\\u091b',u'\\u091c',u'\\u091d',u'\\u0966',u'\\u0967',u'\\u0968',u'\\u0969',u'\\u096a',u'\\u096b',u'\\u096c',u'\\u096d',u'\\u096e',u'\\u096f']\n",
    "#\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "# loading the 'captcha.jpg' image..\n",
    "test_image = cv2.imread(\"205.png\")   # to enter the name of image...\n",
    "image = cv2.resize(test_image, (32,32))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#ret, image1 = cv2.threshold(image, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = np.expand_dims(image, axis=3)\n",
    "print(\"[INFO] loading network...\")\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"HindiModel2.h5\")  # directory of our model in my PC.\n",
    "lists = model.predict(image)[0]  ## only one letter per image...\n",
    "print(labels[np.argmax(lists)])\n",
    "\t\n",
    "#Â© 2021 GitHub, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¤ž\n"
     ]
    }
   ],
   "source": [
    "print(u'\\u091E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
